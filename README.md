# ğŸ§  HuggingFace GPT-2 ìƒì„± ì œì–´ ì‹¤í—˜ (temperature, top_k, top_p)

## ğŸ“Œ ëª©í‘œ
- í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì´ ë‹¤ì–‘í•œ ì„¤ì •ê°’ì— ë”°ë¼ ì–¼ë§ˆë‚˜ ë‹¤ë¥´ê²Œ ë°˜ì‘í•˜ëŠ”ì§€ ì‹¤í—˜
- `temperature`, `top_k`, `top_p` íŒŒë¼ë¯¸í„°ì˜ ì—­í•  ì´í•´ ë° ë¹„êµ ë¶„ì„

---

## ğŸ’» ì‹¤ìŠµ ì½”ë“œ

```python
from transformers import pipeline

generator = pipeline("text-generation", model="gpt2")
prompt = input("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")

settings = [
    {"temperature": 0.7, "top_k": 50, "top_p": 0.95},
    {"temperature": 1.0, "top_k": 50, "top_p": 0.95},
    {"temperature": 1.2, "top_k": 50, "top_p": 0.95},
    {"temperature": 0.7, "top_k": 10, "top_p": 0.9},
    {"temperature": 1.0, "top_k": 100, "top_p": 0.8},
]

for i, setting in enumerate(settings):
    print(f"\n=== ê²°ê³¼ {i+1} | Temp: {setting['temperature']} | Top-k: {setting['top_k']} | Top-p: {setting['top_p']} ===")
    output = generator(prompt, max_length=50, num_return_sequences=1, **setting)
    print(output[0]['generated_text'])

| íŒŒë¼ë¯¸í„°          | ì„¤ëª…                                                        |
| ------------- | --------------------------------------------------------- |
| `temperature` | í™•ë¥  ë¶„í¬ì˜ "ë‚ ì¹´ë¡œì›€" ì¡°ì ˆ. ë‚®ìœ¼ë©´ ë³´ìˆ˜ì , ë†’ìœ¼ë©´ ì°½ì˜ì . (ë³´í†µ 0.7 \~ 1.2 ì‚¬ì´ ì‚¬ìš©) |
| `top_k`       | í™•ë¥ ì´ ë†’ì€ ìƒìœ„ kê°œ í† í°ë§Œ ìƒ˜í”Œë§ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©                              |
| `top_p`       | ëˆ„ì  í™•ë¥  p ì´í•˜ì¸ í† í°ë“¤ë§Œ ê³ ë ¤ (nucleus sampling)                    |

